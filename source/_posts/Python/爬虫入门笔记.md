---
title: çˆ¬è™«å…¥é—¨ç¬”è®°+å®æˆ˜çˆ¬ç¦åˆ©å§å›¾ç‰‡
date: 2018-04-02 09:43:16
categories: Python
tags: [Spider,Demo,Python]
---

ä»Šå¤©å¼€å§‹å­¦çˆ¬è™«ã€‚çˆ¬ä¸ªå•¥å‘¢è¿˜æ²¡æƒ³å¥½ã€‚ğŸ¤­æˆ‘çš„Pythonå·²ç»é¥¥æ¸´éš¾è€äº†~

<!---more--->
# Notes

## æ­£åˆ™è¡¨è¾¾å¼

```
import re
ptn = r'æ­£åˆ™è¡¨è¾¾å¼'
```

- `re.compile()`å‡½æ•°æ˜¯ä»€ä¹ˆï¼Ÿ
å°†æ­£åˆ™è¡¨è¾¾å¼çš„å­—ç¬¦ä¸²å½¢å¼ç¼–è¯‘ä¸ºPattern**å®ä¾‹**

- æ­£åˆ™å°æŠ„å›¾ç‰‡ å½±å“æ–‡ç« æ’ç‰ˆ æ”¾åˆ°æœ€ä¸‹é¢äº†ã€‚
- Noteï¼šæ•°é‡è¯ç”¨åœ¨ `å­—ç¬¦`æˆ– `()` ä¹‹åï¼Œå°±æ˜¯è¯´å¯¹æ•´ä¸ª `()` ç”Ÿæ•ˆ

## urllib
### è¯»ç½‘é¡µ

```
from urllib.request import urlopen

# utf-8è§£ç 
html = urlopen("https://o--o.win").read().decode('utf-8')
print(html)
```
### ä¸‹è½½

```
from urllib.request import urlretrieve
urlretrieve(IMAGE_URL, './img/image1.png')
```

## BeautifulSoup 

[å®˜æ–¹æ–‡æ¡£](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/index.html)

è¿™æ‰æ˜¯æ­£é¤ï¼Ÿ
Exï¼š

```python
from bs4 import BeautifulSoup
from urllib.request import urlopen
import re
import random
#import webbrowser

base_url = "https://baike.baidu.com"
his = ["/item/%e5%91%a8%e6%9d%b0%e4%bc%a6"]

#his = his.encode('uft-8')
for i in range(5):
    print(i)
    url = base_url + his[-1]
    
    html = urlopen(url).read().decode('utf-8')
    
    #webbrowser.open(url)
    
    soup = BeautifulSoup(html,features='lxml')
    
    print(soup.find('h1').get_text(),'\nåç¼€ï¼š',his[0])
    #æ­£åˆ™æ‰¾åˆ° å±æ€§hrefæ˜¯/item/å¼€å¤´ çš„ aæ ‡ç­¾
    sub_urls = soup.find_all('a',{"target":"_blank","href":re.compile("/item/")})
    
    #éšæœºé€‰å–ä¸€ä¸ªaæ ‡ç­¾ä¸­çš„hrefå±æ€§å€¼ï¼Œæ¥åˆ°hisåã€‚
    his.append(random.sample(sub_urls,1)[0]['href'])
    
    #sample(population, k)ä»listä¸­éšæœºæŠ½kä¸ªå…ƒç´ ï¼Œä¹Ÿå°±æ˜¯è¯´æŠ½å®Œçš„ç»“æœè¿˜æ˜¯ä¸ªlistï¼Œå› æ­¤å…ˆè·Ÿäº†ä¸ª[0]ã€‚
```
è‹¥æƒ³åŠ å…¥å®¹é”™,æœ€åä¸€å¥æ”¹æˆ:

```Python
 if len(sub_urls) != 0:
        his.append(random.sample(sub_urls, 1)[0]['href'])
    else:
        # no valid sub link found
        his.pop()
```


## Requests

å¼ºå¤§çš„å¤–éƒ¨éœ€æ±‚æ¨¡å—
[å®˜æ–¹æ–‡æ¡£](http://docs.python-requests.org/zh_CN/latest/)
### Get

```Python
import requests
import webbrowser
param = {"wd": "ç‚«çŒ¿"}  # æœç´¢çš„ä¿¡æ¯
r = requests.get('http://www.baidu.com/s', params=param)
print(r.url)
webbrowser.open(r.url)
```
### Post

```python
data = {'firstname': 'è«çƒ¦', 'lastname': 'å‘¨'}
r = requests.post('http://pythonscraping.com/files/processing.php', data=data)
print(r.text)
```

### ä¸‹è½½

```python
r = requests.get(IMAGE_URL)
with open('./img/image2.png', 'wb') as f:
    f.write(r.content)
```
 requests èƒ½è®©ä½ ä¸‹ä¸€ç‚¹, ä¿å­˜ä¸€ç‚¹, è€Œä¸æ˜¯è¦å…¨éƒ¨ä¸‹è½½å®Œæ‰èƒ½ä¿å­˜å»å¦å¤–çš„åœ°æ–¹. è¿™å°±æ˜¯ä¸€ä¸ª chunk ä¸€ä¸ª chunk çš„ä¸‹è½½. ä½¿ç”¨ r.iter_content(chunk_size) æ¥æ§åˆ¶æ¯ä¸ª chunk çš„å¤§å°, ç„¶ååœ¨æ–‡ä»¶ä¸­å†™å…¥è¿™ä¸ª chunk å¤§å°çš„æ•°æ®.

```
r = requests.get(IMAGE_URL, stream=True)    # stream loading

with open('./img/image3.png', 'wb') as f:
    for chunk in r.iter_content(chunk_size=32):
        f.write(chunk)
```
# å®æˆ˜
è¿™æ ·åŸºæœ¬å¯ä»¥å…¥é—¨äº†ã€‚
å°±æ¥çˆ¬ä¸€ä¸‹æˆ‘æ¯å¤©éƒ½è¦ä¸Šçš„ç¦åˆ©ç½‘å€ç¦åˆ©å§å§ã€‚ç¦åˆ©å§æ¯å¤©æœ‰ä¸ªæ–‡ç« å«æ±‡æ€»ã€‚é‡Œé¢å……æ»¡äº†MMã€‚å°±æ‹¿è¿™äº›MMç»ƒæ‰‹äº†~
Demo1ï¼š

```
from bs4 import BeautifulSoup
import requests

base_URL = "http://fuliba.net/20180"
for i in range(1,10):
    URL = base_URL+str(i)+".html"
    
    print("ç¬¬ %s æœŸ" % i)
    html = requests.get(URL).text
    
    soup = BeautifulSoup(html,features="lxml")
    
    imgs = soup.find_all('img',{"class":"alignnone size-large"})
    
    for img in imgs:
        url = img['src']
        r = requests.get(url,stream=True)
        #å›¾ç‰‡åœ°å€ç”¨ / åˆ†å‰²ï¼Œå†é€‰æœ€åä¸€å—ä½œæ–‡ä»¶å
        image_name = url.split('/')[-1]
        with open('/Users/lixs/Pictures/%s' % image_name, 'wb') as f:
            for chunk in r.iter_content(chunk_size=128):
                f.write(chunk)
        print('Saved %s' % image_name)
```
è¿è¡Œç»“æœï¼š
![](http://p66eruxmw.bkt.clouddn.com/15229998430539.jpg)
æˆ˜æœï¼š
![](http://p66eruxmw.bkt.clouddn.com/15229999645914.jpg)


# Problems


## TypeError: expected string or bytes-like object
å¯¹ç€ç½‘ä¸Šæ•™ç¨‹ï¼Œå¼€é—¨å°±é‡åˆ°è¿™ä¸ªæŠ¥é”™ã€‚
æœäº†ä¸‹ï¼ŒåŸæ¥æ˜¯
`re.findall(r"<title>(.+?)</title>", html)`
è¿™ç§å†™æ³•æ˜¯Python2çš„ã€‚
åœ¨Python3ä¸­åªéœ€è¦æ”¹å†™æˆ
`res = re.findall(r"<title>(.+?)</title>", str(html))`

## ç™¾åº¦ä¸ºä»€ä¹ˆè¦ç”¨Getè€Œä¸ç”¨Postå‘¢ï¼Ÿ
äºæ˜¯æœåˆ°è¿™ç¯‡æ–‡ç« 
[ä¸ºä»€ä¹ˆæœ‰äº†posté‚£ä¹ˆå¤šä¼˜ç‚¹ï¼Œè¿˜æœ‰è¿˜å¤šç½‘ç«™ç”¨getï¼Œæ¯”å¦‚ç™¾åº¦æœç´¢](https://blog.csdn.net/yansong_8686/article/details/48638957)

## ç½‘å€æ˜¯ä¸­æ–‡çš„æƒ…å†µ

`html = urlopen("https://baike.baidu.com/item/å‘¨æ°ä¼¦/").read().decode('utf-8')`
å¾ˆæ˜æ˜¾è™½ç„¶ `decode('utf-8')`å¯ä»¥è§£å†³**ç½‘é¡µ**å†…å®¹æ˜¯ä¸­æ–‡çš„é—®é¢˜ï¼Œ
å¯å½“**ç½‘å€**æ˜¯ä¸­æ–‡çš„æ—¶å€™ï¼Œè¿˜æ˜¯ä¼šæŠ¥é”™
`UnicodeEncodeError: 'ascii' codec can't encode characters in position 10-12: ordinal not in range(128)`

> å½“æˆ‘åœ¨åšå®¢é‡Œå†™ä¸‹ä¸Šé¢è¿™è¡Œå­—çš„æ—¶å€™ï¼Œ
> æˆ‘å°±çªå‘å¥‡æƒ³è¦å†urlå­—ç¬¦ä¸²ådecode()ä¸€ä¸‹ï¼Œ
> å“ˆå“ˆï¼Œå»è¯•è¯•ã€‚
> å“ˆå“ˆ,ä¸è¡Œã€‚

äºæ˜¯ä¹æœåˆ°è¿™ä¸¤ç¯‡æ–‡ç« ï¼š
[å…³äºURLç¼–ç ](http://www.ruanyifeng.com/blog/2010/02/url_encoding.html)
[å­—ç¬¦ç¼–ç ç¬”è®°ï¼šASCIIï¼ŒUnicode å’Œ UTF-8](http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html)
**æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼š**
[åœ¨çº¿Unicodeç¼–ç è½¬æ¢](http://tool.chinaz.com/Tools/Unicode.aspx)

åæ¥å‘ç°å¦‚æœç›´æ¥ç”¨Requestsï¼Œä¸ä¼šæœ‰è¿™ç§é—®é¢˜ã€‚


# æ­£åˆ™è¡¨è¾¾å¼å°æŠ„
![æ­£åˆ™è¡¨è¾¾å¼å°æŠ„](http://p66eruxmw.bkt.clouddn.com/15226337908654.jpg)

